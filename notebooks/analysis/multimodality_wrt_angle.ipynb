{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import copy\n",
    "import tqdm\n",
    "from open_anything_diffusion.metrics.trajectory import flow_metrics, normalize_trajectory\n",
    "initialize(config_path=\"../../configs\", version_base=\"1.3\")\n",
    "cfg = compose(config_name=\"eval_sim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from open_anything_diffusion.models.modules.dit_models import DGDiT\n",
    "# from open_anything_diffusion.models.flow_diffuser_dgdit import (\n",
    "#     FlowTrajectoryDiffuserSimulationModule_DGDiT,\n",
    "# )\n",
    "# network = DGDiT(\n",
    "#     in_channels=3,\n",
    "#     depth=5,\n",
    "#     hidden_size=128,\n",
    "#     patch_size=1,\n",
    "#     num_heads=4,\n",
    "#     n_points=cfg.dataset.n_points,\n",
    "# ).cuda()\n",
    "# model = FlowTrajectoryDiffuserSimulationModule_DGDiT(\n",
    "#     network, inference_cfg=cfg.inference, model_cfg=cfg.model\n",
    "# ).cuda()\n",
    "# model.eval()\n",
    "\n",
    "# ckpt = torch.load('/home/yishu/open_anything_diffusion/logs/train_trajectory_diffuser_dgdit/2024-03-10/10-57-58/checkpoints/epoch=364-step=63875-val_loss=0.00-weights-only.ckpt')\n",
    "# network.load_state_dict(\n",
    "#     {k.partition(\".\")[2]: v for k, v, in ckpt[\"state_dict\"].items()}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from open_anything_diffusion.models.modules.dit_models import DiT\n",
    "# from open_anything_diffusion.models.flow_diffuser_dit import (\n",
    "#     FlowTrajectoryDiffuserSimulationModule_DiT,\n",
    "# )\n",
    "# network = DiT(\n",
    "#     in_channels=3 + 3,\n",
    "#     depth=5,\n",
    "#     hidden_size=128,\n",
    "#     num_heads=4,\n",
    "#     learn_sigma=True,\n",
    "# ).cuda()\n",
    "# model = FlowTrajectoryDiffuserSimulationModule_DiT(\n",
    "#     network, inference_cfg=cfg.inference, model_cfg=cfg.model\n",
    "# ).cuda()\n",
    "# model.eval()\n",
    "\n",
    "# ckpt = torch.load(\"/home/yishu/open_anything_diffusion/logs/train_trajectory_diffuser_dit/2024-03-30/07-12-41/checkpoints/epoch=359-step=199080-val_loss=0.00-weights-only.ckpt\",)\n",
    "# network.load_state_dict(\n",
    "#     {k.partition(\".\")[2]: v for k, v, in ckpt[\"state_dict\"].items()}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rpad.pyg.nets.pointnet2 as pnp\n",
    "# from open_anything_diffusion.models.flow_trajectory_predictor import FlowSimulationInferenceModule\n",
    "# network = pnp.PN2Dense(\n",
    "#     in_channels=0,\n",
    "#     out_channels=3 * cfg.inference.trajectory_len,\n",
    "#     p=pnp.PN2DenseParams(),\n",
    "# )\n",
    "# ckpt = torch.load('/home/yishu/open_anything_diffusion/logs/train_trajectory_pn++/2024-03-18/12-13-31/checkpoints/epoch=78-step=3476-val_loss=0.00-weights-only.ckpt')\n",
    "# # ckpt = torch.load('/home/yishu/open_anything_diffusion/logs/train_trajectory_pn++/2024-05-26/02-37-08/checkpoints/epoch=98-step=109395-val_loss=0.00-weights-only.ckpt')\n",
    "# network.load_state_dict(\n",
    "#     {k.partition(\".\")[2]: v for k, v, in ckpt[\"state_dict\"].items()}\n",
    "# )\n",
    "# model = FlowSimulationInferenceModule(\n",
    "#     network, mask_input_channel=False\n",
    "# )\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.models.modules.dit_models import PN2HisDiT\n",
    "from open_anything_diffusion.models.modules.history_encoder import HistoryEncoder\n",
    "from open_anything_diffusion.models.flow_diffuser_hispndit import (\n",
    "    FlowTrajectoryDiffuserSimulationModule_HisPNDiT,\n",
    ")\n",
    "\n",
    "class InferenceConfig:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 1\n",
    "        self.trajectory_len = 1\n",
    "        self.mask_input_channel = False\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "class ModelConfig:\n",
    "    def __init__(self):\n",
    "        self.num_train_timesteps = 100\n",
    "\n",
    "model_config = ModelConfig()\n",
    "\n",
    "network = {\n",
    "    \"DiT\": PN2HisDiT(\n",
    "        history_embed_dim=128,\n",
    "        in_channels=3,\n",
    "        depth=5,\n",
    "        hidden_size=128,\n",
    "        num_heads=4,\n",
    "        # depth=8,\n",
    "        # hidden_size=256,\n",
    "        # num_heads=4,\n",
    "        learn_sigma=True,\n",
    "    ).cuda(),\n",
    "    \"History\": HistoryEncoder(\n",
    "        history_dim=128,\n",
    "        history_len=1,\n",
    "        batch_norm=True,\n",
    "        transformer=False,\n",
    "        repeat_dim=False,\n",
    "    ).cuda(),\n",
    "}\n",
    "ckpt_file = \"/home/yishu/open_anything_diffusion/logs/train_trajectory_diffuser_hispndit/2024-05-25/02-00-54/checkpoints/epoch=399-step=331600-val_loss=0.00-weights-only.ckpt\"\n",
    "model = FlowTrajectoryDiffuserSimulationModule_HisPNDiT(\n",
    "    network, inference_cfg=inference_config, model_cfg=model_config\n",
    ").cuda()\n",
    "model.load_from_ckpt(ckpt_file)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_ids = [\"8877\", \"9065\", \"9410\", \"8867\", \"9388\", \"8893\"]\n",
    "obj_id = door_ids[3]\n",
    "# obj_id = \"12248\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rpad.partnet_mobility_utils.data import PMObject\n",
    "pm_dir = os.path.expanduser(\"~/datasets/partnet-mobility/raw\")\n",
    "# env = PMSuctionSim(obj_id, pm_dir, gui=gui)\n",
    "raw_data = PMObject(os.path.join(pm_dir, obj_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_joints = raw_data.semantics.by_type(\n",
    "    \"hinge\"\n",
    ") + raw_data.semantics.by_type(\"slider\")\n",
    "print(available_joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_joints = [joint.name for joint in available_joints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.simulations.suction import GTFlowModel, PMSuctionSim\n",
    "env = PMSuctionSim(obj_id, pm_dir, gui=False)\n",
    "gt_model = GTFlowModel(raw_data, env)\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet as p\n",
    "\n",
    "for joint in available_joints:\n",
    "    info = p.getJointInfo(\n",
    "        env.render_env.obj_id,\n",
    "        env.render_env.link_name_to_index[joint],\n",
    "        env.render_env.client_id,\n",
    "    )\n",
    "    init_angle, target_angle = info[8], info[9]\n",
    "    env.set_joint_state(joint, init_angle)\n",
    "    # print(init_angle, target_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_link = available_joints[0]\n",
    "info = p.getJointInfo(\n",
    "    env.render_env.obj_id,\n",
    "    env.render_env.link_name_to_index[target_link],\n",
    "    env.render_env.client_id,\n",
    ")\n",
    "init_angle, target_angle = info[8], info[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.set_joint_state(target_link, init_angle + np.linspace(0, 1, 20)[-1] * (target_angle - init_angle))\n",
    "# env.set_joint_state(target_link, target_angle)\n",
    "pc_obs = env.render(filter_nonobj_pts=True, n_pts=1200)\n",
    "rgb, depth, seg, P_cam, P_world, pc_seg, segmap = pc_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_ixs = pc_seg == env.render_env.link_name_to_index[target_link]\n",
    "gt_flow = gt_model(pc_obs)\n",
    "print(gt_flow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "animation = FlowNetAnimation()\n",
    "animation.add_trace(\n",
    "    torch.as_tensor(P_world),\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([P_world]),\n",
    "    torch.as_tensor([np.zeros((1200, 3))]),\n",
    "    \"red\",\n",
    ")\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "animation = FlowNetAnimation()\n",
    "animation.add_trace(\n",
    "    torch.as_tensor(P_world[link_ixs]),\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([P_world[link_ixs]]),\n",
    "    torch.as_tensor([gt_flow[link_ixs].numpy() * 2]),\n",
    "    \"red\",\n",
    ")\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "animation = FlowNetAnimation()\n",
    "colors = np.random.rand(len(link_ixs), 3)  # Shape (1000, 3)\n",
    "# Convert the random colors to hexadecimal format\n",
    "colors_hex = ['rgb({}, {}, {})'.format(int(r*255), int(g*255), int(b*255)) for r, g, b in colors]\n",
    "animation.add_trace(\n",
    "    torch.as_tensor(P_world[link_ixs]),\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([P_world[link_ixs]]),\n",
    "    torch.as_tensor([np.random.randn(len(gt_flow[link_ixs]), 3)]),\n",
    "    # torch.as_tensor([gt_flow[link_ixs].numpy() * 2]),\n",
    "    # colors_hex,\n",
    "    \"red\"\n",
    ")\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# colors = np.random.rand(1200, 3)  # Shape (1000, 3)\n",
    "\n",
    "# # Convert the random colors to hexadecimal format\n",
    "# colors_hex = ['rgb({}, {}, {})'.format(int(r*255), int(g*255), int(b*255)) for r, g, b in colors]\n",
    "# fig = go.Figure(data=[go.Scatter3d(\n",
    "#     x=P_world[:, 0],\n",
    "#     y=P_world[:, 1],\n",
    "#     z=P_world[:, 2],\n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=5,\n",
    "#         color=colors_hex,  # Set color to the array of random colors\n",
    "#         opacity=0.8\n",
    "#     )\n",
    "# )])\n",
    "\n",
    "# # Step 4: Set plot titles\n",
    "# fig.update_layout(\n",
    "#     title='Predicted Noise',\n",
    "#     scene=dict(\n",
    "#         xaxis_title='X',\n",
    "#         yaxis_title='Y',\n",
    "#         zaxis_title='Z'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Step 5: Show plot\n",
    "# fig.show()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "colors = np.random.randn(50, 3)\n",
    "plt.figure(figsize=(3, 6))\n",
    "plt.imshow(colors, aspect='auto', cmap='gray')\n",
    "plt.colorbar(label='Value')\n",
    "plt.title('1200 * 3 Matrix Visualized as 120 * 30 Heatmap')\n",
    "plt.xlabel('dim = 3 (x, y, z)')\n",
    "plt.ylabel('dim = point count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different open angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(init_angle, np.linspace(init_angle, target_angle, 10), target_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_sample_cnts = 100\n",
    "trial_cnts = 20 # 1\n",
    "xs = []\n",
    "rmses = []\n",
    "cosines = []\n",
    "\n",
    "past_gt_flow = None\n",
    "past_pcd = None\n",
    "\n",
    "for angle_ratio, angle in zip(\n",
    "        np.linspace(0, 100, angle_sample_cnts),\n",
    "        np.linspace(init_angle, target_angle, angle_sample_cnts)\n",
    "    ):\n",
    "    # print(angle_ratio)\n",
    "    env.set_joint_state(target_link, angle)\n",
    "    # env.set_joint_state(target_link, target_angle)\n",
    "    pc_obs = env.render(filter_nonobj_pts=True, n_pts=1200)\n",
    "    rgb, depth, seg, P_cam, P_world, pc_seg, segmap = pc_obs\n",
    "\n",
    "    gt_flow = gt_model(pc_obs)\n",
    "    # nonzero_gt_flowixs = torch.where(gt_flow.norm(dim=-1) != 0.0)\n",
    "    nonzero_gt_flowixs = pc_seg == env.render_env.link_name_to_index[target_link]\n",
    "    gt_flow_nz = gt_flow[nonzero_gt_flowixs]\n",
    "\n",
    "    for i in tqdm.tqdm(range(trial_cnts)):\n",
    "        with torch.no_grad():\n",
    "            # pred_flow = model(copy.deepcopy(pc_obs))[:, 0, :]\n",
    "            pred_flow = model(\n",
    "                copy.deepcopy(pc_obs),\n",
    "                history_pcd=past_pcd,\n",
    "                history_flow=past_gt_flow,\n",
    "            )[:, 0, :]\n",
    "\n",
    "        pred_flow_nz = pred_flow[nonzero_gt_flowixs]\n",
    "\n",
    "        xs.append(angle_ratio)\n",
    "        # cos_dist = torch.cosine_similarity(pred_flow_nz, gt_flow_nz, dim=-1).mean()\n",
    "        # ys.append(cos_dist)\n",
    "\n",
    "        rmse, cos_dist, mag_error = flow_metrics(pred_flow_nz, gt_flow_nz)\n",
    "        rmses.append(rmse)\n",
    "        cosines.append(cos_dist)\n",
    "\n",
    "    past_gt_flow = gt_flow.cpu().numpy()\n",
    "    past_pcd = P_world\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.scatter(xs, cosines, c='gray', s=20, alpha=0.2, edgecolors='black')\n",
    "ax.scatter(xs, cosines, c='orange', s=20, alpha=0.2, edgecolors='red')\n",
    "plt.title(f'Door {obj_id}')\n",
    "plt.xlabel('Open ratio (%)')\n",
    "plt.ylabel('Cosine similarity')\n",
    "# plt.ylabel('Mag error (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.scatter(xs, rmses, c='gray', s=20, edgecolors='black')\n",
    "ax.scatter(xs, rmses, c='orange', s=20, alpha=0.2, edgecolors='red')\n",
    "plt.title(f'Door {obj_id}')\n",
    "plt.xlabel('Open ratio (%)')\n",
    "plt.ylabel('RMSE')\n",
    "# plt.ylabel('Mag error (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "cosines_flowbot = copy.deepcopy(cosines)\n",
    "rmses_flowbot = copy.deepcopy(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction flow plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_ratio = 0\n",
    "angle = init_angle + angle_ratio * (target_angle - init_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.set_joint_state(target_link, angle - (0.2 * (target_angle - init_angle)))\n",
    "# env.set_joint_state(target_link, target_angle)\n",
    "pc_obs = env.render(filter_nonobj_pts=True, n_pts=1200)\n",
    "rgb, depth, seg, P_cam, P_world, pc_seg, segmap = pc_obs\n",
    "\n",
    "gt_flow = gt_model(pc_obs)\n",
    "history_pcd = P_world\n",
    "history_flow = gt_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.set_joint_state(target_link, angle)\n",
    "pc_obs = env.render(filter_nonobj_pts=True, n_pts=1200)\n",
    "rgb, depth, seg, P_cam, P_world, pc_seg, segmap = pc_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(angle_ratio)\n",
    "# env.set_joint_state(target_link, target_angle)\n",
    "\n",
    "gt_flow = gt_model(pc_obs)\n",
    "# nonzero_gt_flowixs = torch.where(gt_flow.norm(dim=-1) != 0.0)\n",
    "nonzero_gt_flowixs = pc_seg == env.render_env.link_name_to_index[target_link]\n",
    "gt_flow_nz = gt_flow[nonzero_gt_flowixs]\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_flow, intermediates = model(copy.deepcopy(pc_obs), return_intermediate=True)\n",
    "    pred_flow = pred_flow[:, 0, :]\n",
    "    # pred_flow = model(copy.deepcopy(pc_obs), history_pcd, history_flow.numpy())[:, 0, :]\n",
    "\n",
    "pred_flow_nz = pred_flow[nonzero_gt_flowixs]\n",
    "\n",
    "# xs.append(angle_ratio)\n",
    "# # cos_dist = torch.cosine_similarity(pred_flow_nz, gt_flow_nz, dim=-1).mean()\n",
    "# # ys.append(cos_dist)\n",
    "\n",
    "rmse, cos_dist, mag_error = flow_metrics(pred_flow_nz, gt_flow_nz)\n",
    "# rmses.append(rmse)\n",
    "# cosines.append(cos_dist)\n",
    "print(rmse, cos_dist, mag_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diffusion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates[0].squeeze().flatten(start_dim=1, end_dim=2).permute(1, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "from open_anything_diffusion.metrics.trajectory import normalize_trajectory\n",
    "animation = FlowNetAnimation()\n",
    "for i in range(101):\n",
    "    if i % 1 != 0:\n",
    "        continue\n",
    "    flow = intermediates[i].squeeze().flatten(start_dim=1, end_dim=2).permute(1, 0).unsqueeze(1)\n",
    "    flow = normalize_trajectory(flow)\n",
    "    print(flow.shape)\n",
    "    \n",
    "    # print(flow[mask])\n",
    "    # segmented_flow = np.zeros_like(flow, dtype=np.float32)\n",
    "    # segmented_flow[mask] = flow[mask]\n",
    "    # print(\"seg\", segmented_flow, \"flow\", flow)\n",
    "    animation.add_trace(\n",
    "        torch.as_tensor(P_world),\n",
    "        # torch.as_tensor([pcd[mask]]),\n",
    "        # torch.as_tensor([flow[mask]]),\n",
    "        torch.as_tensor([P_world]),\n",
    "        torch.as_tensor([flow[:, 0, :].cpu().numpy() * 3]),\n",
    "        \"red\",\n",
    "    )\n",
    "\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diffusion visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "animation = FlowNetAnimation()\n",
    "animation.add_trace(\n",
    "    torch.as_tensor(P_world),\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([P_world[nonzero_gt_flowixs]]),\n",
    "    torch.as_tensor([pred_flow_nz.cpu().numpy() * 2]),\n",
    "    \"red\",\n",
    ")\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grasp point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import tqdm\n",
    "from open_anything_diffusion.metrics.trajectory import flow_metrics\n",
    "\n",
    "angle_sample_cnts = 20\n",
    "trial_cnts = 100\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for angle_ratio, angle in zip(\n",
    "        np.linspace(5, 100, angle_sample_cnts),\n",
    "        np.linspace(init_angle, target_angle, angle_sample_cnts)\n",
    "    ):\n",
    "    print(angle_ratio)\n",
    "    env.set_joint_state(target_link, angle)\n",
    "    # env.set_joint_state(target_link, target_angle)\n",
    "    pc_obs = env.render(filter_nonobj_pts=True, n_pts=1200)\n",
    "    rgb, depth, seg, P_cam, P_world, pc_seg, segmap = pc_obs\n",
    "\n",
    "    gt_flow = gt_model(pc_obs)\n",
    "    affordance = np.zeros_like(gt_flow)\n",
    "    # nonzero_gt_flowixs = torch.where(gt_flow.norm(dim=-1) != 0.0)\n",
    "    nonzero_gt_flowixs = pc_seg == env.render_env.link_name_to_index[target_link]\n",
    "    gt_flow_nz = gt_flow[nonzero_gt_flowixs]\n",
    "\n",
    "    for i in tqdm.tqdm(range(trial_cnts)):\n",
    "        with torch.no_grad():\n",
    "            pred_flow = model(copy.deepcopy(pc_obs))[:, 0, :]\n",
    "\n",
    "        pred_flow_nz = pred_flow[nonzero_gt_flowixs]\n",
    "        flow_norm = pred_flow.norm(p=2, dim=-1)\n",
    "        max_point_id = np.argmax(flow_norm)\n",
    "        affordance[max_point_id][0] += 1\n",
    "\n",
    "        xs.append(angle_ratio)\n",
    "        # cos_dist = torch.cosine_similarity(pred_flow_nz, gt_flow_nz, dim=-1).mean()\n",
    "        # ys.append(cos_dist)\n",
    "\n",
    "        rmse, cos_dist, mag_error = flow_metrics(pred_flow_nz, gt_flow_nz)\n",
    "        ys.append(mag_error)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affordance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "animation = FlowNetAnimation()\n",
    "animation.add_trace(\n",
    "    torch.as_tensor(P_world),\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([P_world]),\n",
    "    # torch.as_tensor([np.array(gt_flow)]),\n",
    "    torch.as_tensor([affordance]),\n",
    "    \"red\",\n",
    ")\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openany",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
