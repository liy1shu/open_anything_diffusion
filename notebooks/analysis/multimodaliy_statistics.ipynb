{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count how many objects have multi-modal predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import copy\n",
    "import tqdm\n",
    "from open_anything_diffusion.metrics.trajectory import flow_metrics, normalize_trajectory\n",
    "initialize(config_path=\"../../configs\", version_base=\"1.3\")\n",
    "cfg = compose(config_name=\"eval_sim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.models.modules.dit_models import PN2HisDiT\n",
    "from open_anything_diffusion.models.modules.history_encoder import HistoryEncoder\n",
    "from open_anything_diffusion.models.flow_diffuser_hispndit import (\n",
    "    FlowTrajectoryDiffuserSimulationModule_HisPNDiT,\n",
    ")\n",
    "\n",
    "class InferenceConfig:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 1\n",
    "        self.trajectory_len = 1\n",
    "        self.mask_input_channel = False\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "class ModelConfig:\n",
    "    def __init__(self):\n",
    "        self.num_train_timesteps = 100\n",
    "\n",
    "model_config = ModelConfig()\n",
    "\n",
    "network = {\n",
    "    \"DiT\": PN2HisDiT(\n",
    "        history_embed_dim=128,\n",
    "        in_channels=3,\n",
    "        depth=5,\n",
    "        hidden_size=128,\n",
    "        num_heads=4,\n",
    "        # depth=8,\n",
    "        # hidden_size=256,\n",
    "        # num_heads=4,\n",
    "        learn_sigma=True,\n",
    "    ).cuda(),\n",
    "    \"History\": HistoryEncoder(\n",
    "        history_dim=128,\n",
    "        history_len=1,\n",
    "        batch_norm=True,\n",
    "        transformer=False,\n",
    "        repeat_dim=False,\n",
    "    ).cuda(),\n",
    "}\n",
    "# ckpt_file = \"/home/yishu/open_anything_diffusion/logs/train_trajectory_diffuser_hispndit/2024-05-25/02-00-54/checkpoints/epoch=399-step=331600-val_loss=0.00-weights-only.ckpt\"\n",
    "# ckpt_file = \"/home/yishu/open_anything_diffusion/pretrained/fullset_half_half_hispndit.ckpt\"\n",
    "ckpt_file = \"/home/yishu/open_anything_diffusion/pretrained/door_half_half_hispndit.ckpt\"\n",
    "model = FlowTrajectoryDiffuserSimulationModule_HisPNDiT(\n",
    "    network, inference_cfg=inference_config, model_cfg=model_config\n",
    ").cuda()\n",
    "model.load_from_ckpt(ckpt_file)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "def load_obj_id_to_category(toy_dataset=None):\n",
    "    id_to_cat = {}\n",
    "    if toy_dataset is None:\n",
    "        # Extract existing classes.\n",
    "        with open(f\"../../scripts/umpnet_data_split_new.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for _, category_dict in data.items():\n",
    "            for category, split_dict in category_dict.items():\n",
    "                for train_or_test, id_list in split_dict.items():\n",
    "                    for id in id_list:\n",
    "                        id_to_cat[id] = f\"{category}_{train_or_test}\"\n",
    "\n",
    "    else:\n",
    "        with open(f\"../../scripts/umpnet_object_list.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        for split in [\"train-train\", \"train-test\"]:\n",
    "            # for split in [\"train-test\"]:\n",
    "            for id in toy_dataset[split]:\n",
    "                id_to_cat[id] = split\n",
    "    return id_to_cat\n",
    "\n",
    "pm_dir = os.path.expanduser(\"~/datasets/partnet-mobility/convex\")\n",
    "id_to_cat = load_obj_id_to_category(None)\n",
    "with open('/home/yishu/open_anything_diffusion/scripts/movable_links_fullset_000.json', 'r') as f:\n",
    "    obj_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.models.modules.dit_models import PN2HisDiT\n",
    "from open_anything_diffusion.models.modules.history_encoder import HistoryEncoder\n",
    "from open_anything_diffusion.models.flow_diffuser_hispndit import FlowTrajectoryDiffuserSimulationModule_HisPNDiT\n",
    "\n",
    "ckpt_file = \"/home/yishu/open_anything_diffusion/pretrained/fullset_half_half_hispndit.ckpt\"\n",
    "\n",
    "network = {\n",
    "    \"DiT\": PN2HisDiT(\n",
    "        history_embed_dim=128,\n",
    "        in_channels=3,\n",
    "        depth=5,\n",
    "        hidden_size=128,\n",
    "        num_heads=4,\n",
    "        learn_sigma=True,\n",
    "    ).cuda(),\n",
    "    \"History\": HistoryEncoder(\n",
    "        history_dim=128,\n",
    "        history_len=1,\n",
    "        batch_norm=True,\n",
    "        transformer=False,\n",
    "        repeat_dim=False,\n",
    "    ).cuda(),\n",
    "}\n",
    "\n",
    "class InferenceConfig:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 1\n",
    "        self.trajectory_len = 1\n",
    "        self.mask_input_channel = False\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "class ModelConfig:\n",
    "    def __init__(self):\n",
    "        self.num_train_timesteps = 100\n",
    "\n",
    "model_config = ModelConfig()\n",
    "\n",
    "model = FlowTrajectoryDiffuserSimulationModule_HisPNDiT(\n",
    "    network, inference_cfg=inference_config, model_cfg=model_config\n",
    ")\n",
    "model.load_from_ckpt(ckpt_file)\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.simulations.suction import GTFlowModel, PMSuctionSim\n",
    "from open_anything_diffusion.metrics.trajectory import flow_metrics\n",
    "from tqdm import tqdm\n",
    "import pybullet as p\n",
    "from rpad.partnet_mobility_utils.data import PMObject\n",
    "\n",
    "all_categories = list(set(list(id_to_cat.values())))\n",
    "all_categories_name = list(set([name.split('_')[0] for name in all_categories]))\n",
    "print(all_categories_name)\n",
    "\n",
    "test_categories = ['Door_test', 'Door_train']\n",
    "\n",
    "trial_cnts = 20\n",
    "multimodal = {}\n",
    "can_be_correct = {}\n",
    "counts = {}\n",
    "mags = {}\n",
    "cosines = {}\n",
    "rmse_records = {}\n",
    "for name in all_categories:\n",
    "    multimodal[name] = 0\n",
    "    can_be_correct[name] = 0\n",
    "    counts[name] = 0\n",
    "\n",
    "    mags[name] = []\n",
    "    cosines[name] = []\n",
    "    rmse_records[name] = []\n",
    "\n",
    "might_fail_trials = []\n",
    "for obj_id, joint_ids in tqdm(obj_dict.items()):\n",
    "    if id_to_cat[obj_id] not in test_categories:\n",
    "        continue\n",
    "    # print(obj_id, joint_ids)\n",
    "    for joint_id in joint_ids:\n",
    "        print(obj_id, id_to_cat[obj_id], counts.keys())\n",
    "        counts[id_to_cat[obj_id]] += 1\n",
    "        raw_data = PMObject(os.path.join(pm_dir, obj_id))\n",
    "        env = PMSuctionSim(obj_id, pm_dir, gui=False)\n",
    "        gt_model = GTFlowModel(raw_data, env)\n",
    "        env.reset()\n",
    "\n",
    "        target_link = joint_id\n",
    "        info = p.getJointInfo(\n",
    "            env.render_env.obj_id,\n",
    "            env.render_env.link_name_to_index[target_link],\n",
    "            env.render_env.client_id,\n",
    "        )\n",
    "        init_angle, target_angle = info[8], info[9]\n",
    "\n",
    "        env.set_joint_state(target_link, init_angle + np.linspace(0, 1, 20)[0] * (target_angle - init_angle))\n",
    "        # env.set_joint_state(target_link, target_angle)\n",
    "        pc_obs = env.render(filter_nonobj_pts=True, n_pts=1200)\n",
    "        rgb, depth, seg, P_cam, P_world, pc_seg, segmap = pc_obs\n",
    "\n",
    "        link_ixs = pc_seg == env.render_env.link_name_to_index[target_link]\n",
    "        gt_flow = gt_model(pc_obs)\n",
    "        nonzero_gt_flowixs = pc_seg == env.render_env.link_name_to_index[target_link]\n",
    "        gt_flow_nz = gt_flow[nonzero_gt_flowixs]\n",
    "\n",
    "        has_pos = False\n",
    "        has_neg = False\n",
    "        rmses = []\n",
    "        cos_dists = []\n",
    "        mag_errors = []\n",
    "\n",
    "        for i in tqdm(range(trial_cnts)):\n",
    "            with torch.no_grad():\n",
    "                # pred_flow = model(copy.deepcopy(pc_obs))[:, 0, :]\n",
    "                pred_flow = model(\n",
    "                    copy.deepcopy(pc_obs),\n",
    "                    history_pcd=None,\n",
    "                    history_flow=None,\n",
    "                )[:, 0, :]\n",
    "\n",
    "            pred_flow_nz = pred_flow[nonzero_gt_flowixs]\n",
    "\n",
    "            rmse, cos_dist, mag_error = flow_metrics(pred_flow_nz, gt_flow_nz)\n",
    "            rmses.append(rmse)\n",
    "            cos_dists.append(cos_dist)\n",
    "            mag_errors.append(mag_error)\n",
    "            if cos_dist > 0.8 and mag_error < 0.3:\n",
    "                has_pos = True\n",
    "            if cos_dist < -0.6 or mag_error > 0.5:\n",
    "                has_neg = True\n",
    "\n",
    "        can_be_correct[id_to_cat[obj_id]] += has_pos\n",
    "        multimodal[id_to_cat[obj_id]] += (has_pos and has_neg)\n",
    "        mags[id_to_cat[obj_id]].append(mag_errors)\n",
    "        cosines[id_to_cat[obj_id]].append(cos_dists)\n",
    "        rmse_records[id_to_cat[obj_id]].append(rmses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_be_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the results and do analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl \n",
    "with open('./multimodal_dict.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def load_obj_id_to_category(toy_dataset=None):\n",
    "    id_to_cat = {}\n",
    "    if toy_dataset is None:\n",
    "        # Extract existing classes.\n",
    "        with open(f\"../../scripts/umpnet_data_split_new.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for _, category_dict in data.items():\n",
    "            for category, split_dict in category_dict.items():\n",
    "                for train_or_test, id_list in split_dict.items():\n",
    "                    for id in id_list:\n",
    "                        id_to_cat[id] = f\"{category}_{train_or_test}\"\n",
    "\n",
    "    else:\n",
    "        with open(f\"../../scripts/umpnet_object_list.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        for split in [\"train-train\", \"train-test\"]:\n",
    "            # for split in [\"train-test\"]:\n",
    "            for id in toy_dataset[split]:\n",
    "                id_to_cat[id] = split\n",
    "    return id_to_cat\n",
    "\n",
    "pm_dir = os.path.expanduser(\"~/datasets/partnet-mobility/convex\")\n",
    "id_to_cat = load_obj_id_to_category(None)\n",
    "with open('/home/yishu/open_anything_diffusion/scripts/movable_links_fullset_000.json', 'r') as f:\n",
    "    obj_dict = json.load(f)\n",
    "\n",
    "all_categories = list(set(list(id_to_cat.values())))\n",
    "all_categories_name = list(set([name.split('_')[0] for name in all_categories]))\n",
    "\n",
    "counts = {}\n",
    "for name in all_categories:\n",
    "    counts[name] = 0\n",
    "for obj_id, joint_ids in tqdm(list(obj_dict.items())[:861]):\n",
    "    if 'train' not in id_to_cat[obj_id]:\n",
    "        continue\n",
    "    # print(obj_id, joint_ids)\n",
    "    for joint_id in joint_ids:\n",
    "        print(obj_id, id_to_cat[obj_id], counts.keys())\n",
    "        counts[id_to_cat[obj_id]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = data['counts']\n",
    "mags = data['mags']\n",
    "cosines = data['cosines']\n",
    "rmses = data['rmses']\n",
    "multimodal = data['multimodal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_multimodal(mag_trials, cosine_trials, rmse_trials):\n",
    "    has_positive = False\n",
    "    has_negative = False\n",
    "    for mag, cosine, rmse in zip(mag_trials, cosine_trials, rmse_trials):\n",
    "        # print(mag, cosine, rmse)\n",
    "        if rmse < 0.2:  # Good\n",
    "            has_positive = True\n",
    "        elif rmse > 0.8:  # Bad\n",
    "            has_negative = True\n",
    "\n",
    "    return has_positive and has_negative\n",
    "    # print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_multimodal = {}\n",
    "for category in counts.keys():\n",
    "    if counts[category] == 0:\n",
    "        continue\n",
    "    new_multimodal[category] = 0\n",
    "\n",
    "for category in new_multimodal.keys():\n",
    "    for i in range(counts[category]):\n",
    "        new_multimodal[category] += judge_multimodal(mags[category][i], cosines[category][i], rmses[category][i])\n",
    "    new_multimodal[category] /= counts[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.bar([cat.replace('_test', '') for cat in list(new_multimodal.keys())], list(new_multimodal.values()), color='skyblue')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Multimodal Prediction Ratio (Train set)')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Ratio')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig('multimodal_test.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openany",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
