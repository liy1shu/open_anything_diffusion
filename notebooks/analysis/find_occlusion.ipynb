{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from open_anything_diffusion.simulations.simulation import *\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.set_printoptions(precision=10)  # Set higher precision for PyTorch outputs\n",
    "np.set_printoptions(precision=10)\n",
    "from hydra import compose, initialize\n",
    "\n",
    "initialize(config_path=\"../../configs\", version_base=\"1.3\")\n",
    "cfg = compose(config_name=\"eval_sim_switch\")\n",
    "# cfg = compose(config_name=\"eval_sim\")\n",
    "\n",
    "from open_anything_diffusion.models.flow_diffuser_dit import (\n",
    "    FlowTrajectoryDiffuserSimulationModule_DiT,\n",
    ")\n",
    "from open_anything_diffusion.models.flow_diffuser_pndit import (\n",
    "    FlowTrajectoryDiffuserSimulationModule_PNDiT,\n",
    ")\n",
    "from open_anything_diffusion.models.modules.history_encoder import HistoryEncoder\n",
    "from open_anything_diffusion.models.modules.dit_models import DiT, PN2DiT, PN2HisDiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpad.pyg.nets.pointnet2 as pnp\n",
    "network = pnp.PN2Dense(\n",
    "    in_channels=0,\n",
    "    out_channels=3,\n",
    "    p=pnp.PN2DenseParams(),\n",
    ")\n",
    "\n",
    "ckpt_file = \"/home/yishu/open_anything_diffusion/pretrained/fullset_half_half_flowbotRO.ckpt\"\n",
    "\n",
    "# Load the network weights.\n",
    "ckpt = torch.load(ckpt_file)\n",
    "network.load_state_dict(\n",
    "    {k.partition(\".\")[2]: v for k, v, in ckpt[\"state_dict\"].items()}\n",
    ")\n",
    "network.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to find occluded examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_dir = os.path.expanduser(\"~/datasets/partnet-mobility/convex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_obj_id_to_category(toy_dataset=None):\n",
    "    id_to_cat = {}\n",
    "    if toy_dataset is None:\n",
    "        # Extract existing classes.\n",
    "        with open(f\"../../scripts/umpnet_data_split_new.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for _, category_dict in data.items():\n",
    "            for category, split_dict in category_dict.items():\n",
    "                for train_or_test, id_list in split_dict.items():\n",
    "                    for id in id_list:\n",
    "                        id_to_cat[id] = f\"{category}_{train_or_test}\"\n",
    "\n",
    "    else:\n",
    "        with open(f\"../../scripts/umpnet_object_list.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        for split in [\"train-train\", \"train-test\"]:\n",
    "            # for split in [\"train-test\"]:\n",
    "            for id in toy_dataset[split]:\n",
    "                id_to_cat[id] = split\n",
    "    return id_to_cat\n",
    "\n",
    "id_to_cat = load_obj_id_to_category(None)\n",
    "with open('/home/yishu/open_anything_diffusion/scripts/movable_links_fullset_000.json', 'r') as f:\n",
    "    obj_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = list(set(list(id_to_cat.values())))\n",
    "all_categories_name = list(set([name.split('_')[0] for name in all_categories]))\n",
    "print(all_categories_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "might_occlude_names = ['WashingMachine', 'Door', 'Safe', 'Dishwasher', 'Refrigerator', 'Microwave', 'Oven']\n",
    "might_occludes = [name + '_test' for name in might_occlude_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "might_be_occluded_trials = []\n",
    "\n",
    "for obj_id, joint_ids in obj_dict.items():\n",
    "    if id_to_cat[obj_id] not in might_occludes:\n",
    "        continue\n",
    "    print(obj_id, joint_ids)\n",
    "    for joint_id in joint_ids:\n",
    "        raw_data = PMObject(os.path.join(pm_dir, obj_id))\n",
    "        # available_joints = raw_data.semantics.by_type(\"hinge\") + raw_data.semantics.by_type(\n",
    "        #     \"slider\"\n",
    "        # )\n",
    "        # available_joints = [joint.name for joint in available_joints]\n",
    "        # target_link = available_joints[joint_id]\n",
    "        # print(target_link)\n",
    "        target_link = joint_id\n",
    "\n",
    "        # # History\n",
    "        # trial_figs, trial_results, all_signals = trial_with_diffuser_history(\n",
    "        #     obj_id=obj_id,\n",
    "        #     model=switch_model,\n",
    "        #     history_model=switch_model,\n",
    "        #     n_step=30,\n",
    "        #     gui=False,\n",
    "        #     website=True,\n",
    "        #     all_joint=False,\n",
    "        #     available_joints=[target_link],\n",
    "        #     consistency_check=True,\n",
    "        #     history_filter=True,\n",
    "        #     analysis=True\n",
    "        # )\n",
    "        # (sim_trajectory, update_history_signals, cc_cnts, sgp_signals, visual_all_points, visual_link_ixs, visual_grasp_points_idx, visual_grasp_points, visual_flows) = all_signals[0]\n",
    "\n",
    "        # FlowBot\n",
    "        trial_figs, trial_results, all_signals = trial_with_prediction(\n",
    "            obj_id=obj_id,\n",
    "            network=network,\n",
    "            n_step=30,\n",
    "            gui=False,\n",
    "            all_joint=False,\n",
    "            available_joints=[target_link],\n",
    "            website=True,\n",
    "            sgp=False,\n",
    "            analysis=True,\n",
    "        )\n",
    "        # print(trial_results, all_signals)\n",
    "        try:\n",
    "            (sim_trajectory, update_history_signals, cc_cnts, sgp_signals, visual_all_points, visual_link_ixs, visual_grasp_points_idx, visual_grasp_points, visual_flows) = all_signals[0]\n",
    "            for step in range(1, len(sim_trajectory)):\n",
    "                if sim_trajectory[step] < sim_trajectory[step-1]:\n",
    "                    might_be_occluded_trials.append([trial_figs, trial_results, all_signals[0]])\n",
    "                    print(f\"Found! id: {obj_id}\")\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "\n",
    "# breakpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openany",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
