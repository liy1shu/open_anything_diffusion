{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "initialize(config_path=\"../../configs\", version_base=\"1.3\")\n",
    "cfg = compose(config_name=\"eval_sim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from open_anything_diffusion.models.modules.dit_models import DGDiT\n",
    "from open_anything_diffusion.models.flow_diffuser_dgdit import (\n",
    "    FlowTrajectoryDiffuserSimulationModule_DGDiT,\n",
    ")\n",
    "network = DGDiT(\n",
    "    in_channels=3,\n",
    "    depth=5,\n",
    "    hidden_size=128,\n",
    "    patch_size=1,\n",
    "    num_heads=4,\n",
    "    n_points=cfg.dataset.n_points,\n",
    ").cuda()\n",
    "model = FlowTrajectoryDiffuserSimulationModule_DGDiT(\n",
    "    network, inference_cfg=cfg.inference, model_cfg=cfg.model\n",
    ").cuda()\n",
    "model.eval()\n",
    "\n",
    "ckpt = torch.load('/home/yishu/open_anything_diffusion/logs/train_trajectory_diffuser_dgdit/2024-03-10/10-57-58/checkpoints/epoch=364-step=63875-val_loss=0.00-weights-only.ckpt')\n",
    "network.load_state_dict(\n",
    "    {k.partition(\".\")[2]: v for k, v, in ckpt[\"state_dict\"].items()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from open_anything_diffusion.models.modules.dit_models import DiT\n",
    "# from open_anything_diffusion.models.flow_diffuser_dit import (\n",
    "#     FlowTrajectoryDiffuserSimulationModule_DiT,\n",
    "# )\n",
    "# network = DiT(\n",
    "#     in_channels=3 + 3,\n",
    "#     depth=5,\n",
    "#     hidden_size=128,\n",
    "#     num_heads=4,\n",
    "#     learn_sigma=True,\n",
    "# ).cuda()\n",
    "# model = FlowTrajectoryDiffuserSimulationModule_DiT(\n",
    "#     network, inference_cfg=cfg.inference, model_cfg=cfg.model\n",
    "# ).cuda()\n",
    "# model.eval()\n",
    "\n",
    "# ckpt = torch.load('/home/yishu/open_anything_diffusion/logs/train_trajectory_diffuser_dit/2024-03-10/10-54-13/checkpoints/epoch=459-step=80500-val_loss=0.00-weights-only.ckpt')\n",
    "# network.load_state_dict(\n",
    "#     {k.partition(\".\")[2]: v for k, v, in ckpt[\"state_dict\"].items()}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rpad.pyg.nets.pointnet2 as pnp\n",
    "# from open_anything_diffusion.models.flow_trajectory_predictor import FlowSimulationInferenceModule\n",
    "# network = pnp.PN2Dense(\n",
    "#     in_channels=0,\n",
    "#     out_channels=3 * cfg.inference.trajectory_len,\n",
    "#     p=pnp.PN2DenseParams(),\n",
    "# )\n",
    "# ckpt = torch.load('/home/yishu/open_anything_diffusion/logs/train_trajectory_pn++/2024-03-18/12-13-31/checkpoints/epoch=78-step=3476-val_loss=0.00-weights-only.ckpt')\n",
    "# network.load_state_dict(\n",
    "#     {k.partition(\".\")[2]: v for k, v, in ckpt[\"state_dict\"].items()}\n",
    "# )\n",
    "# model = FlowSimulationInferenceModule(\n",
    "#     network, False\n",
    "# )\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_ids = [\"8867\", \"8983\", \"8994\", \"9003\", \"9263\", \"9393\"]\n",
    "obj_id = door_ids[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rpad.partnet_mobility_utils.data import PMObject\n",
    "pm_dir = os.path.expanduser(\"~/datasets/partnet-mobility/raw\")\n",
    "# env = PMSuctionSim(obj_id, pm_dir, gui=gui)\n",
    "raw_data = PMObject(os.path.join(pm_dir, obj_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_joints = raw_data.semantics.by_type(\n",
    "    \"hinge\"\n",
    ") + raw_data.semantics.by_type(\"slider\")\n",
    "print(available_joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_joints = [joint.name for joint in available_joints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.simulations.suction import GTFlowModel, PMSuctionSim\n",
    "env = PMSuctionSim(obj_id, pm_dir, gui=False)\n",
    "gt_model = GTFlowModel(raw_data, env)\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_link = available_joints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet as p\n",
    "info = p.getJointInfo(\n",
    "    env.render_env.obj_id,\n",
    "    env.render_env.link_name_to_index[target_link],\n",
    "    env.render_env.client_id,\n",
    ")\n",
    "init_angle, target_angle = info[8], info[9]\n",
    "print(init_angle, target_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.set_joint_state(target_link, init_angle + np.linspace(0, 1, 20)[-1] * (target_angle - init_angle))\n",
    "# env.set_joint_state(target_link, target_angle)\n",
    "pc_obs = env.render(filter_nonobj_pts=True, n_pts=1200)\n",
    "rgb, depth, seg, P_cam, P_world, pc_seg, segmap = pc_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "animation = FlowNetAnimation()\n",
    "animation.add_trace(\n",
    "    torch.as_tensor(P_world),\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([P_world]),\n",
    "    torch.as_tensor([np.zeros((1200, 3))]),\n",
    "    \"red\",\n",
    ")\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different open angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(init_angle, np.linspace(init_angle, target_angle, 10), target_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import tqdm\n",
    "from open_anything_diffusion.metrics.trajectory import flow_metrics\n",
    "\n",
    "angle_sample_cnts = 20\n",
    "trial_cnts = 20\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for angle_ratio, angle in zip(\n",
    "        np.linspace(0, 100, angle_sample_cnts),\n",
    "        np.linspace(init_angle, target_angle, angle_sample_cnts)\n",
    "    ):\n",
    "    print(angle_ratio)\n",
    "    env.set_joint_state(target_link, angle)\n",
    "    # env.set_joint_state(target_link, target_angle)\n",
    "    pc_obs = env.render(filter_nonobj_pts=True, n_pts=1200)\n",
    "    rgb, depth, seg, P_cam, P_world, pc_seg, segmap = pc_obs\n",
    "\n",
    "    gt_flow = gt_model(pc_obs)\n",
    "    nonzero_gt_flowixs = torch.where(gt_flow.norm(dim=-1) != 0.0)\n",
    "    gt_flow_nz = gt_flow[nonzero_gt_flowixs]\n",
    "\n",
    "    for i in tqdm.tqdm(range(trial_cnts)):\n",
    "        with torch.no_grad():\n",
    "            pred_flow = model(copy.deepcopy(pc_obs))[:, 0, :]\n",
    "\n",
    "        pred_flow_nz = pred_flow[nonzero_gt_flowixs]\n",
    "\n",
    "        xs.append(angle_ratio)\n",
    "        # cos_dist = torch.cosine_similarity(pred_flow_nz, gt_flow_nz, dim=-1).mean()\n",
    "        # ys.append(cos_dist)\n",
    "\n",
    "        rmse, cos_dist, mag_error = flow_metrics(pred_flow_nz, gt_flow_nz)\n",
    "        ys.append(mag_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(f'Door {obj_id}')\n",
    "plt.xlabel('Open ratio (%)')\n",
    "# plt.ylabel('Cosine similarity (%)')\n",
    "plt.ylabel('Mag error (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grasp point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import tqdm\n",
    "from open_anything_diffusion.metrics.trajectory import flow_metrics\n",
    "\n",
    "angle_sample_cnts = 20\n",
    "trial_cnts = 100\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for angle_ratio, angle in zip(\n",
    "        np.linspace(5, 100, angle_sample_cnts),\n",
    "        np.linspace(init_angle, target_angle, angle_sample_cnts)\n",
    "    ):\n",
    "    print(angle_ratio)\n",
    "    env.set_joint_state(target_link, angle)\n",
    "    # env.set_joint_state(target_link, target_angle)\n",
    "    pc_obs = env.render(filter_nonobj_pts=True, n_pts=1200)\n",
    "    rgb, depth, seg, P_cam, P_world, pc_seg, segmap = pc_obs\n",
    "\n",
    "    gt_flow = gt_model(pc_obs)\n",
    "    affordance = np.zeros_like(gt_flow)\n",
    "    nonzero_gt_flowixs = torch.where(gt_flow.norm(dim=-1) != 0.0)\n",
    "    gt_flow_nz = gt_flow[nonzero_gt_flowixs]\n",
    "\n",
    "    for i in tqdm.tqdm(range(trial_cnts)):\n",
    "        with torch.no_grad():\n",
    "            pred_flow = model(copy.deepcopy(pc_obs))[:, 0, :]\n",
    "\n",
    "        pred_flow_nz = pred_flow[nonzero_gt_flowixs]\n",
    "        flow_norm = pred_flow.norm(p=2, dim=-1)\n",
    "        max_point_id = np.argmax(flow_norm)\n",
    "        affordance[max_point_id][0] += 1\n",
    "\n",
    "        xs.append(angle_ratio)\n",
    "        # cos_dist = torch.cosine_similarity(pred_flow_nz, gt_flow_nz, dim=-1).mean()\n",
    "        # ys.append(cos_dist)\n",
    "\n",
    "        rmse, cos_dist, mag_error = flow_metrics(pred_flow_nz, gt_flow_nz)\n",
    "        ys.append(mag_error)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affordance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "animation = FlowNetAnimation()\n",
    "animation.add_trace(\n",
    "    torch.as_tensor(P_world),\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([P_world]),\n",
    "    # torch.as_tensor([np.array(gt_flow)]),\n",
    "    torch.as_tensor([affordance]),\n",
    "    \"red\",\n",
    ")\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openany",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
