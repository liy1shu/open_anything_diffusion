{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_id_dict = {\n",
    "    # \"flowbot\": '15ecnnm8',  # run-{}-train_metric_table:v0\n",
    "    # \"traj1\": 'wcx2tyyn',\n",
    "    # \"traj5\": 'z9japwzr',\n",
    "    # \"traj10\": 'dzng8oc9',\n",
    "    # \"traj15\": 'ujjttwjx',\n",
    "    # \"traj20\": '66vi6gbz',\n",
    "    \"diffuser1\": \"udh6n9fh\",\n",
    "    \"diffuser5\": \"xbxuwn3s\",\n",
    "    \"diffuser10\": \"qsq7b7d2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "for model in artifact_id_dict.keys():\n",
    "    artifact_id = artifact_id_dict[model]\n",
    "    for mode in [\"train\", \"val\", \"test\"]:\n",
    "        artifact = api.artifact(f'r-pad/open_anything_diffusion/run-{artifact_id}-{mode}_metric_table:v0')\n",
    "        artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "neat_dfs = {}\n",
    "desired_columns_order = {\n",
    "    \"train\": [\"model\", \"unweighted_mean\", \"class_mean\", \"FoldingChair\", \"Kettle\", \"Laptop\", \"Microwave\", \"Refrigerator\",\"Stapler\", \"StorageFurniture\", \"Switch\", \"Toilet\",\t\"TrashCan\",\t\"Window\"],\n",
    "    \"test\": [\"model\", \"unweighted_mean\", \"class_mean\", \"Box\",\"Bucket\",\"Dishwasher\",\"Door\",\"KitchenPot\", \"Oven\",\"Phone\",\"Safe\",\"Table\",\"WashingMachine\"],\n",
    "    \"val\":[\"model\", \"unweighted_mean\", \"class_mean\", \"FoldingChair\", \"Kettle\", \"Laptop\", \"Microwave\", \"Refrigerator\",\"Stapler\", \"StorageFurniture\", \"Switch\", \"Toilet\",\t\"TrashCan\",\t\"Window\"],\n",
    "}\n",
    "model_order = artifact_id_dict.keys()\n",
    "for mode in [\"train\", \"val\", \"test\"]:\n",
    "    neat_dfs[mode] = pd.DataFrame()\n",
    "    chao_df = pd.DataFrame()\n",
    "    for model in artifact_id_dict.keys():\n",
    "        artifact_id = artifact_id_dict[model]\n",
    "        artifact_local_path = f'/home/yishu/open_anything_diffusion/notebooks/artifacts/run-{artifact_id}-{mode}_metric_table:v0/{mode}_metric_table.table.json'\n",
    "        with open(artifact_local_path) as file:\n",
    "            json_dict = json.load(file)\n",
    "        df = pd.DataFrame(json_dict[\"data\"], columns=json_dict[\"columns\"]).T\n",
    "        df.columns = df.loc['category']\n",
    "        df['model'] = model\n",
    "        df.drop('category', inplace=True)\n",
    "        df = df.reindex(columns=desired_columns_order[mode])\n",
    "        chao_df = pd.concat([chao_df, df])\n",
    "    for metric in [\"cos_dist\", \"rmse\", \"mag_error\"]:\n",
    "        new_df = chao_df.loc[metric].sort_values(by='model', key=lambda x: x.map({v: i for i, v in enumerate(model_order)}))\n",
    "        neat_dfs[mode] = pd.concat([neat_dfs[mode], new_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neat_dfs['train'].to_csv('./diffuser_train_metrics.csv')\n",
    "neat_dfs['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neat_dfs['val'].to_csv('./diffuser_val_metrics.csv')\n",
    "neat_dfs['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neat_dfs['test'].to_csv('./diffuser_test_metrics.csv')\n",
    "neat_dfs['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = artifact_id_dict.keys()\n",
    "# all_dfs['train']['model'] = pd.Categorical(all_dfs['train']['model'], categories=model_order, ordered=True)\n",
    "metric_df = pd.DataFrame()\n",
    "for metric in [\"cos_dist\", \"rmse\", \"mag_error\"]:\n",
    "    new_df = all_dfs['train'].loc[metric].sort_values(by='model', key=lambda x: x.map({v: i for i, v in enumerate(model_order)}))\n",
    "    metric_df = pd.concat([metric_df, new_df])\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs['test']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openany",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
