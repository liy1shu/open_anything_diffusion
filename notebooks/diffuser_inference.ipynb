{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/home/yishu/open_anything_diffusion/logs/train_trajectory/2023-08-31/16-13-10/checkpoints/epoch=394-step=310470-val_loss=0.00-weights-only.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.models.flow_trajectory_diffuser import (\n",
    "    FlowTrajectoryDiffusionModule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "initialize(config_path=\"../configs\", version_base=\"1.3\")\n",
    "cfg = compose(config_name=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpad.pyg.nets.pointnet2 as pnp\n",
    "network = pnp.PN2Dense(\n",
    "    in_channels=67,\n",
    "    out_channels=3,\n",
    "    p=pnp.PN2DenseParams(),\n",
    ")\n",
    "\n",
    "model = FlowTrajectoryDiffusionModule(network, cfg.training, cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load(ckpt_path)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.datasets.flow_trajectory import FlowTrajectoryDataModule\n",
    "datamodule = FlowTrajectoryDataModule(\n",
    "    root=\"/home/yishu/datasets/partnet-mobility\",\n",
    "    batch_size=1,\n",
    "    num_workers=30,\n",
    "    n_proc=2,\n",
    "    seed=42,\n",
    "    trajectory_len=cfg.training.trajectory_len,  # Only used when training trajectory model\n",
    ")\n",
    "\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "val_dataloader = datamodule.train_val_dataloader()\n",
    "samples = list(enumerate(train_dataloader))\n",
    "# breakpoint()\n",
    "sample = samples[1][1].cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fix_noise /= torch.linalg.norm(fix_noise, dim=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = samples[30][1].cuda()\n",
    "batch = sample\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.metrics.trajectory import artflownet_loss, flow_metrics, normalize_trajectory\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "animation = FlowNetAnimation()\n",
    "pcd = sample.pos.cpu().numpy()\n",
    "mask = sample.mask.cpu().long().numpy()\n",
    "\n",
    "fix_noise = torch.randn_like(sample.delta, device=\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    bs = batch.delta.shape[0] // 1200\n",
    "    # batch.traj_noise = torch.randn_like(batch.delta, device=\"cuda\")\n",
    "    batch.traj_noise = fix_noise\n",
    "    # batch.traj_noise = normalize_trajectory(batch.traj_noise)\n",
    "    # breakpoint()\n",
    "\n",
    "    # import time\n",
    "    # batch_time = 0\n",
    "    # model_time = 0\n",
    "    # noise_scheduler_time = 0\n",
    "    # self.noise_scheduler_inference.set_timesteps(self.num_inference_timesteps)\n",
    "    # print(self.noise_scheduler_inference.timesteps)\n",
    "    # for t in self.noise_scheduler_inference.timesteps:\n",
    "    for t in model.noise_scheduler.timesteps:\n",
    "        \n",
    "        # tm = time.time()\n",
    "        batch.timesteps = torch.zeros(bs, device=model.device) + t  # Uniform t steps\n",
    "        batch.timesteps = batch.timesteps.long()\n",
    "        # batch_time += time.time() - tm\n",
    "\n",
    "        # tm = time.time()\n",
    "        model_output = model(batch)          # bs * 1200, traj_len * 3\n",
    "        model_output = model_output.reshape(model_output.shape[0], -1, 3)  # bs * 1200, traj_len, 3\n",
    "        \n",
    "        batch.traj_noise = model.noise_scheduler.step(\n",
    "            # batch.traj_noise = self.noise_scheduler_inference.step(\n",
    "            model_output.reshape(\n",
    "                -1, model.sample_size, model_output.shape[1], model_output.shape[2]\n",
    "            ),\n",
    "            t,\n",
    "            batch.traj_noise.reshape(\n",
    "                -1, model.sample_size, model_output.shape[1], model_output.shape[2]\n",
    "            ),\n",
    "        ).prev_sample\n",
    "        batch.traj_noise = torch.flatten(batch.traj_noise, start_dim=0, end_dim=1)\n",
    "\n",
    "        # print(batch.traj_noise)\n",
    "        if t % 50 == 0 or t == 999:\n",
    "            flow = batch.traj_noise.squeeze().cpu().numpy()\n",
    "            # print(flow[mask])\n",
    "            # segmented_flow = np.zeros_like(flow, dtype=np.float32)\n",
    "            # segmented_flow[mask] = flow[mask]\n",
    "            # print(\"seg\", segmented_flow, \"flow\", flow)\n",
    "            animation.add_trace(\n",
    "                torch.as_tensor(pcd),\n",
    "                # torch.as_tensor([pcd[mask]]),\n",
    "                # torch.as_tensor([flow[mask].detach().cpu().numpy()]),\n",
    "                torch.as_tensor([pcd]),\n",
    "                torch.as_tensor([flow]),\n",
    "                \"red\",\n",
    "            )\n",
    "\n",
    "    f_pred = batch.traj_noise\n",
    "    f_pred = normalize_trajectory(f_pred)\n",
    "    # largest_mag: float = torch.linalg.norm(\n",
    "    #     f_pred, ord=2, dim=-1\n",
    "    # ).max()\n",
    "    # f_pred = f_pred / (largest_mag + 1e-6)\n",
    "\n",
    "    # Compute the loss.\n",
    "    n_nodes = torch.as_tensor([d.num_nodes for d in batch.to_data_list()]).to(\"cuda\")  # type: ignore\n",
    "    f_ix = batch.mask.bool()\n",
    "    f_target = batch.delta\n",
    "    f_target = normalize_trajectory(f_target)\n",
    "\n",
    "    f_target = f_target.float()\n",
    "    # loss = artflownet_loss(f_pred, f_target, n_nodes)\n",
    "\n",
    "    # Compute some metrics on flow-only regions.\n",
    "    rmse, cos_dist, mag_error = flow_metrics(\n",
    "        f_pred[f_ix], batch.delta[f_ix]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.delta[f_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_mag: float = torch.linalg.norm(\n",
    "    f_pred, ord=2, dim=-1\n",
    ").max()\n",
    "print(f_pred / (largest_mag + 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_trajectory(f_pred)[f_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pred[f_ix]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openany",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
