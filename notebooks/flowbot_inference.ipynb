{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flowbot inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/home/yishu/open_anything_diffusion/logs/train_trajectory/2023-11-15/23-59-12/checkpoints/epoch=199-step=9200.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.models.flow_trajectory_predictor import (\n",
    "    FlowTrajectoryTrainingModule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "initialize(config_path=\"../configs\", version_base=\"1.3\")\n",
    "cfg = compose(config_name=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpad.pyg.nets.pointnet2 as pnp\n",
    "network = pnp.PN2Dense(\n",
    "    in_channels=0,\n",
    "    out_channels=3,\n",
    "    p=pnp.PN2DenseParams(),\n",
    ")\n",
    "\n",
    "model = FlowTrajectoryTrainingModule(network, cfg.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load(ckpt_path)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.loader as tgl\n",
    "from open_anything_diffusion.datasets.flow_trajectory_dataset_pyg import FlowTrajectoryPyGDataset\n",
    "from open_anything_diffusion.datasets.flow_trajectory import FlowTrajectoryDataModule\n",
    "datamodule = FlowTrajectoryDataModule(\n",
    "    root=\"/home/yishu/datasets/partnet-mobility\",\n",
    "    batch_size=1,\n",
    "    num_workers=30,\n",
    "    n_proc=2,\n",
    "    seed=42,\n",
    "    trajectory_len=cfg.training.trajectory_len,  # Only used when training trajectory model\n",
    "    # toy_dataset = {\n",
    "    #     \"id\": \"door-1\",\n",
    "    #     \"train-train\": [\"8994\", \"9035\"],\n",
    "    #     \"train-test\": [\"8994\", \"9035\"],\n",
    "    #     \"test\": [\"8867\"],\n",
    "    # }\n",
    "    toy_dataset = {\n",
    "        \"id\": \"door-full-new\",\n",
    "        \"train-train\": [\"8877\", \"8893\", \"8897\", \"8903\", \"8919\", \"8930\", \"8961\", \"8997\", \"9016\", \"9032\", \"9035\", \"9041\", \"9065\", \"9070\", \"9107\", \"9117\", \"9127\", \"9128\", \"9148\", \"9164\", \"9168\", \"9277\", \"9280\", \"9281\", \"9288\", \"9386\", \"9388\", \"9410\"],\n",
    "        \"train-test\": [\"8867\", \"8983\", \"8994\", \"9003\", \"9263\", \"9393\"],\n",
    "        \"test\": [\"8867\", \"8983\", \"8994\", \"9003\", \"9263\", \"9393\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "train_val_dataloader = datamodule.train_val_dataloader()\n",
    "val_dataloader = datamodule.val_dataloader()\n",
    "# unseen_dataloader = datamodule.unseen_dataloader()\n",
    "\n",
    "# datamodule = FlowTrajectoryPyGDataset(\n",
    "#     root=\"/home/yishu/datasets/partnet-mobility/raw\",\n",
    "#     split=\"umpnet-train-test\",\n",
    "#     randomize_joints=True,\n",
    "#     randomize_camera=True,\n",
    "#     # batch_size=1,\n",
    "#     # num_workers=30,\n",
    "#     # n_proc=2,\n",
    "#     seed=42,\n",
    "#     trajectory_len=cfg.training.trajectory_len,  # Only used when training trajectory model\n",
    "# )\n",
    "# unseen_dataloader = tgl.DataLoader(datamodule, 1, shuffle=False, num_workers=0)\n",
    "\n",
    "samples = list(enumerate(train_val_dataloader))\n",
    "# # breakpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.metrics.trajectory import artflownet_loss, flow_metrics, normalize_trajectory\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "import numpy as np\n",
    "\n",
    "@torch.no_grad()\n",
    "def flowbot_visual(batch, model):  # 1 sample batch\n",
    "    model.eval()\n",
    "    \n",
    "    animation = FlowNetAnimation()\n",
    "    pcd = batch.pos.cpu().numpy()\n",
    "    f_pred = model(batch)\n",
    "    f_pred = normalize_trajectory(f_pred[:, None, :])\n",
    "\n",
    "    animation.add_trace(\n",
    "        torch.as_tensor(pcd),\n",
    "        # torch.as_tensor([pcd[mask]]),\n",
    "        # torch.as_tensor([flow[mask]]),\n",
    "        torch.as_tensor([pcd]),\n",
    "        torch.as_tensor([f_pred.squeeze().cpu().numpy()]),\n",
    "        \"red\",\n",
    "    )\n",
    "\n",
    "    # largest_mag: float = torch.linalg.norm(\n",
    "    #     f_pred, ord=2, dim=-1\n",
    "    # ).max()\n",
    "    # f_pred = f_pred / (largest_mag + 1e-6)\n",
    "\n",
    "    # Compute the loss.\n",
    "    n_nodes = torch.as_tensor([d.num_nodes for d in batch.to_data_list()]).to(\"cuda\")  # type: ignore\n",
    "    f_ix = batch.mask.bool()\n",
    "    f_target = batch.delta\n",
    "    f_target = normalize_trajectory(f_target)\n",
    "\n",
    "    f_target = f_target.float()\n",
    "    loss = artflownet_loss(f_pred, f_target, n_nodes)\n",
    "\n",
    "    # Compute some metrics on flow-only regions.\n",
    "    rmse, cos_dist, mag_error = flow_metrics(\n",
    "        f_pred[f_ix], batch.delta[f_ix]\n",
    "    )\n",
    "\n",
    "    return rmse, cos_dist, mag_error, loss, animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmse = 0\n",
    "all_cos_dist = 0\n",
    "all_mag_error = 0\n",
    "all_loss = 0\n",
    "model = model.cuda()\n",
    "for i in range(len(samples)):\n",
    "    sample = samples[i][1].cuda()\n",
    "    batch = sample\n",
    "    rmse, cos_dist, mag_error, loss, animation = flowbot_visual(sample, model)\n",
    "    all_rmse += rmse.item()\n",
    "    all_cos_dist += cos_dist.item()\n",
    "    all_loss += loss.item()\n",
    "    all_mag_error += mag_error.item()\n",
    "\n",
    "all_rmse /= len(samples)\n",
    "all_cos_dist /= len(samples)\n",
    "all_mag_error /= len(samples)\n",
    "all_loss /= len(samples)\n",
    "print(f\"rmse:{all_rmse:.4f}, cos:{all_cos_dist:.4f}, mag:{all_mag_error:.4f}, flowloss:{all_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = samples[15][1].cuda()\n",
    "batch = sample\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, cos_dist, mag_error, loss, animation = flowbot_visual(sample, model)\n",
    "print(f\"rmse:{rmse:.4f}, cos:{cos_dist:.4f}, mag:{mag_error:.4f}, flowloss:{loss:.4f}\")\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse, cos_dist, mag_error, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = samples[1][1].cuda()\n",
    "batch = sample\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, cos_dist, mag_error, loss, animation = flowbot_visual(sample, model)\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse, cos_dist, mag_error, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = samples[0][1].cuda()\n",
    "batch = sample\n",
    "model = model.cuda()\n",
    "\n",
    "rmse, cos_dist, mag_error, loss, animation = flowbot_visual(sample, model)\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse, cos_dist, mag_error, loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openany",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
