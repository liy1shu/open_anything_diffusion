{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "initialize(config_path=\"configs\", version_base=\"1.3\")\n",
    "cfg = compose(config_name=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Door dataset\n",
    "toy_dataset = {\n",
    "    \"id\": \"door-full-new\",\n",
    "    \"train-train\": [\n",
    "        \"8877\",\n",
    "        \"8893\",\n",
    "        \"8897\",\n",
    "        \"8903\",\n",
    "        \"8919\",\n",
    "        \"8930\",\n",
    "        \"8961\",\n",
    "        \"8997\",\n",
    "        \"9016\",\n",
    "        \"9032\",\n",
    "        \"9035\",\n",
    "        \"9041\",\n",
    "        \"9065\",\n",
    "        \"9070\",\n",
    "        \"9107\",\n",
    "        \"9117\",\n",
    "        \"9127\",\n",
    "        \"9128\",\n",
    "        \"9148\",\n",
    "        \"9164\",\n",
    "        \"9168\",\n",
    "        \"9277\",\n",
    "        \"9280\",\n",
    "        \"9281\",\n",
    "        \"9288\",\n",
    "        \"9386\",\n",
    "        \"9388\",\n",
    "        \"9410\",\n",
    "    ],\n",
    "    \"train-test\": [\"8867\", \"8983\", \"8994\", \"9003\", \"9263\", \"9393\"],\n",
    "    \"test\": [\"8867\", \"8983\", \"8994\", \"9003\", \"9263\", \"9393\"],\n",
    "}\n",
    "# special_req = \"half-half\"  # \"fully-closed\"\n",
    "special_req = \"half-half-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_anything_diffusion.datasets.flow_trajectory import FlowTrajectoryDataModule\n",
    "datamodule = FlowTrajectoryDataModule(\n",
    "        root=cfg.dataset.data_dir,\n",
    "        batch_size=cfg.training.batch_size,\n",
    "        num_workers=cfg.resources.num_workers,\n",
    "        n_proc=cfg.resources.n_proc_per_worker,\n",
    "        seed=cfg.seed,\n",
    "        history=\"his\" in cfg.model.name,\n",
    "        randomize_size=cfg.dataset.randomize_size,\n",
    "        augmentation=cfg.dataset.augmentation,\n",
    "        trajectory_len=1,  # Only used when training trajectory model\n",
    "        special_req=special_req,  # special_req=\"fully-closed\"\n",
    "        n_repeat=200\n",
    "        if special_req == \"half-half-01\"\n",
    "        else (50 if special_req is None else 100),\n",
    "        # # TODO: only for toy training!!!!!\n",
    "        toy_dataset=toy_dataset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = datamodule.train_val_dataloader(bsz=1)\n",
    "samples = list(enumerate(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = samples[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = sample.pos\n",
    "flow = sample.delta\n",
    "history = sample.history\n",
    "flow_history = sample.flow_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "\n",
    "animation = FlowNetAnimation()\n",
    "\n",
    "# sampled_points = rot_pcd[np.random.randint(0, pcd.shape[0], 1200)]\n",
    "gt_action = torch.tensor([-1, 0, 0])\n",
    "cosines = []\n",
    "predictions = []\n",
    "animation.add_trace(\n",
    "    pcd,\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([pcd.numpy()]),\n",
    "    torch.as_tensor([flow[:, 0, :].numpy() * 2]),\n",
    "    # torch.as_tensor([pred_flow.cpu().numpy()]* 10),\n",
    "    \"red\",\n",
    ")\n",
    "\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "flip = 0 # 4 flip modes\n",
    "flip_mat = torch.tensor([\n",
    "                        [[1, 0, 0], [0, 1, 0], [0, 0, 1]],    # Normal\n",
    "                        [[1, 0, 0], [0, -1, 0], [0, 0, 1]],    # Left, right\n",
    "                        [[-1, 0, 0], [0, 1, 0], [0, 0, 1]],    # Front, back\n",
    "                        [[-1, 0, 0], [0, -1, 0], [0, 0, 1]]     # Front back & left right\n",
    "                    ]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = FlowNetAnimation()\n",
    "\n",
    "for flip in range(4):\n",
    "    # Add flip\n",
    "    pcd = torch.matmul(sample.pos, flip_mat[flip])\n",
    "    flow = torch.matmul(sample.delta, flip_mat[flip])\n",
    "    history = torch.matmul(sample.history, flip_mat[flip])\n",
    "    flow_history = torch.matmul(sample.flow_history, flip_mat[flip])\n",
    "\n",
    "    # sampled_points = rot_pcd[np.random.randint(0, pcd.shape[0], 1200)]\n",
    "    gt_action = torch.tensor([-1, 0, 0])\n",
    "    cosines = []\n",
    "    predictions = []\n",
    "    animation.add_trace(\n",
    "        pcd,\n",
    "        # torch.as_tensor([pcd[mask]]),\n",
    "        # torch.as_tensor([flow[mask]]),\n",
    "        torch.as_tensor([pcd.numpy()]),\n",
    "        torch.as_tensor([flow[:, 0, :].numpy() * 2]),\n",
    "        # torch.as_tensor([pred_flow.cpu().numpy()]* 10),\n",
    "        \"red\",\n",
    "    )\n",
    "\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOr real robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "path = '/home/yishu/open_anything_diffusion/real_world_pcds/slightly_open_xyz.npy'\n",
    "\n",
    "import torch\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "## Point cloud only\n",
    "animation = FlowNetAnimation()\n",
    "\n",
    "# sampled_points = rot_pcd[np.random.randint(0, pcd.shape[0], 1200)]\n",
    "gt_action = torch.tensor([-1, 0, 0])\n",
    "cosines = []\n",
    "predictions = []\n",
    "animation.add_trace(\n",
    "    torch.as_tensor(pcd),\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([pcd]),\n",
    "    torch.as_tensor([np.zeros((1200, 3)) * 2]),\n",
    "    # torch.as_tensor([pred_flow.cpu().numpy()]* 10),\n",
    "    \"red\",\n",
    ")\n",
    "\n",
    "\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_path = '/home/yishu/open_anything_diffusion/real_world_pcds/xyz.npy'\n",
    "prev_pcd = np.load(prev_path)\n",
    "# prev_rot_pcd = rotate_pcd(prev_pcd)\n",
    "\n",
    "prev_flow_path = '/home/yishu/open_anything_diffusion/real_world_pcds/flow.npy'\n",
    "history_flow = np.load(prev_flow_path)\n",
    "\n",
    "import torch\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "## Point cloud only\n",
    "animation = FlowNetAnimation()\n",
    "\n",
    "animation.add_trace(\n",
    "    torch.as_tensor(prev_pcd),\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([prev_pcd]),\n",
    "    torch.as_tensor([history_flow]),\n",
    "    # torch.as_tensor([pred_flow.cpu().numpy()]* 10),\n",
    "    \"red\",\n",
    ")\n",
    "\n",
    "fig = animation.animate()\n",
    "fig.show()\n",
    "# prev_rot_pcd = rotate_pcd(prev_pcd)\n",
    "\n",
    "prev_flow_path = '/home/yishu/open_anything_diffusion/real_world_pcds/flow.npy'\n",
    "history_flow = np.load(prev_flow_path)\n",
    "\n",
    "import torch\n",
    "from flowbot3d.grasping.agents.flowbot3d import FlowNetAnimation\n",
    "## Point cloud only\n",
    "animation = FlowNetAnimation()\n",
    "\n",
    "animation.add_trace(\n",
    "    torch.as_tensor(prev_pcd),\n",
    "    # torch.as_tensor([pcd[mask]]),\n",
    "    # torch.as_tensor([flow[mask]]),\n",
    "    torch.as_tensor([prev_pcd]),\n",
    "    torch.as_tensor([history_flow]),\n",
    "    # torch.as_tensor([pred_flow.cpu().numpy()]* 10),\n",
    "    \"red\",\n",
    ")\n",
    "\n",
    "fig = animation.animate()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openany",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
